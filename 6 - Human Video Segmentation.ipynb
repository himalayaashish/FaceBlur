{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Video Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 20px; line-height: 30px;\">\n",
    "<ol>\n",
    "    <li> Load model </li>\n",
    "    <li> Load video </li>\n",
    "    <li> Predict the mask for each frame </li>\n",
    "    <li> Join each frame and save them </li>\n",
    "</ol>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import CustomObjectScope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYTHONHASHSEED\"] = str(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 512\n",
    "width = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(\"files\" ,\"unet.h5\")\n",
    "input_video_path = os.path.join(\"test-videos\", \"inputs\", \"Video-2.mp4\")\n",
    "output_video_path = os.path.join(\"test-videos\", \"outputs\", \"Video-2.avi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(y_true, y_pred):\n",
    "    y_true = tf.keras.layers.Flatten()(y_true)\n",
    "    y_pred = tf.keras.layers.Flatten()(y_pred)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    dice = (2. * intersection + 1e-15) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + 1e-15)\n",
    "    return 1.0 - dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with CustomObjectScope({'dice_loss': dice_loss}):\n",
    "    model = tf.keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"UNET\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 512, 512, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)   (None, 518, 518, 3)          0         ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)         (None, 256, 256, 64)         9472      ['conv1_pad[0][0]']           \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalizati  (None, 256, 256, 64)         256       ['conv1_conv[0][0]']          \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)     (None, 256, 256, 64)         0         ['conv1_bn[0][0]']            \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)   (None, 258, 258, 64)         0         ['conv1_relu[0][0]']          \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)   (None, 128, 128, 64)         0         ['pool1_pad[0][0]']           \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2  (None, 128, 128, 64)         4160      ['pool1_pool[0][0]']          \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNo  (None, 128, 128, 64)         256       ['conv2_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activ  (None, 128, 128, 64)         0         ['conv2_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2  (None, 128, 128, 64)         36928     ['conv2_block1_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNo  (None, 128, 128, 64)         256       ['conv2_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activ  (None, 128, 128, 64)         0         ['conv2_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2  (None, 128, 128, 256)        16640     ['pool1_pool[0][0]']          \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2  (None, 128, 128, 256)        16640     ['conv2_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNo  (None, 128, 128, 256)        1024      ['conv2_block1_0_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNo  (None, 128, 128, 256)        1024      ['conv2_block1_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)      (None, 128, 128, 256)        0         ['conv2_block1_0_bn[0][0]',   \n",
      "                                                                     'conv2_block1_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activati  (None, 128, 128, 256)        0         ['conv2_block1_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2  (None, 128, 128, 64)         16448     ['conv2_block1_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNo  (None, 128, 128, 64)         256       ['conv2_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activ  (None, 128, 128, 64)         0         ['conv2_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2  (None, 128, 128, 64)         36928     ['conv2_block2_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNo  (None, 128, 128, 64)         256       ['conv2_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activ  (None, 128, 128, 64)         0         ['conv2_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2  (None, 128, 128, 256)        16640     ['conv2_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNo  (None, 128, 128, 256)        1024      ['conv2_block2_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)      (None, 128, 128, 256)        0         ['conv2_block1_out[0][0]',    \n",
      "                                                                     'conv2_block2_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activati  (None, 128, 128, 256)        0         ['conv2_block2_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2  (None, 128, 128, 64)         16448     ['conv2_block2_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNo  (None, 128, 128, 64)         256       ['conv2_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activ  (None, 128, 128, 64)         0         ['conv2_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2  (None, 128, 128, 64)         36928     ['conv2_block3_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNo  (None, 128, 128, 64)         256       ['conv2_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activ  (None, 128, 128, 64)         0         ['conv2_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2  (None, 128, 128, 256)        16640     ['conv2_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNo  (None, 128, 128, 256)        1024      ['conv2_block3_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)      (None, 128, 128, 256)        0         ['conv2_block2_out[0][0]',    \n",
      "                                                                     'conv2_block3_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activati  (None, 128, 128, 256)        0         ['conv2_block3_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2  (None, 64, 64, 128)          32896     ['conv2_block3_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNo  (None, 64, 64, 128)          512       ['conv3_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activ  (None, 64, 64, 128)          0         ['conv3_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2  (None, 64, 64, 128)          147584    ['conv3_block1_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNo  (None, 64, 64, 128)          512       ['conv3_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activ  (None, 64, 64, 128)          0         ['conv3_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2  (None, 64, 64, 512)          131584    ['conv2_block3_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2  (None, 64, 64, 512)          66048     ['conv3_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNo  (None, 64, 64, 512)          2048      ['conv3_block1_0_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNo  (None, 64, 64, 512)          2048      ['conv3_block1_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)      (None, 64, 64, 512)          0         ['conv3_block1_0_bn[0][0]',   \n",
      "                                                                     'conv3_block1_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activati  (None, 64, 64, 512)          0         ['conv3_block1_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2  (None, 64, 64, 128)          65664     ['conv3_block1_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNo  (None, 64, 64, 128)          512       ['conv3_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activ  (None, 64, 64, 128)          0         ['conv3_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2  (None, 64, 64, 128)          147584    ['conv3_block2_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNo  (None, 64, 64, 128)          512       ['conv3_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activ  (None, 64, 64, 128)          0         ['conv3_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2  (None, 64, 64, 512)          66048     ['conv3_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNo  (None, 64, 64, 512)          2048      ['conv3_block2_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)      (None, 64, 64, 512)          0         ['conv3_block1_out[0][0]',    \n",
      "                                                                     'conv3_block2_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activati  (None, 64, 64, 512)          0         ['conv3_block2_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2  (None, 64, 64, 128)          65664     ['conv3_block2_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNo  (None, 64, 64, 128)          512       ['conv3_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activ  (None, 64, 64, 128)          0         ['conv3_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2  (None, 64, 64, 128)          147584    ['conv3_block3_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNo  (None, 64, 64, 128)          512       ['conv3_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activ  (None, 64, 64, 128)          0         ['conv3_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2  (None, 64, 64, 512)          66048     ['conv3_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNo  (None, 64, 64, 512)          2048      ['conv3_block3_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)      (None, 64, 64, 512)          0         ['conv3_block2_out[0][0]',    \n",
      "                                                                     'conv3_block3_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activati  (None, 64, 64, 512)          0         ['conv3_block3_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2  (None, 64, 64, 128)          65664     ['conv3_block3_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNo  (None, 64, 64, 128)          512       ['conv3_block4_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activ  (None, 64, 64, 128)          0         ['conv3_block4_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2  (None, 64, 64, 128)          147584    ['conv3_block4_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNo  (None, 64, 64, 128)          512       ['conv3_block4_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activ  (None, 64, 64, 128)          0         ['conv3_block4_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2  (None, 64, 64, 512)          66048     ['conv3_block4_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNo  (None, 64, 64, 512)          2048      ['conv3_block4_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)      (None, 64, 64, 512)          0         ['conv3_block3_out[0][0]',    \n",
      "                                                                     'conv3_block4_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activati  (None, 64, 64, 512)          0         ['conv3_block4_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2  (None, 32, 32, 256)          131328    ['conv3_block4_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNo  (None, 32, 32, 256)          1024      ['conv4_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activ  (None, 32, 32, 256)          0         ['conv4_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2  (None, 32, 32, 256)          590080    ['conv4_block1_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNo  (None, 32, 32, 256)          1024      ['conv4_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activ  (None, 32, 32, 256)          0         ['conv4_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2  (None, 32, 32, 1024)         525312    ['conv3_block4_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2  (None, 32, 32, 1024)         263168    ['conv4_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNo  (None, 32, 32, 1024)         4096      ['conv4_block1_0_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNo  (None, 32, 32, 1024)         4096      ['conv4_block1_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)      (None, 32, 32, 1024)         0         ['conv4_block1_0_bn[0][0]',   \n",
      "                                                                     'conv4_block1_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activati  (None, 32, 32, 1024)         0         ['conv4_block1_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2  (None, 32, 32, 256)          262400    ['conv4_block1_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNo  (None, 32, 32, 256)          1024      ['conv4_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activ  (None, 32, 32, 256)          0         ['conv4_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2  (None, 32, 32, 256)          590080    ['conv4_block2_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNo  (None, 32, 32, 256)          1024      ['conv4_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activ  (None, 32, 32, 256)          0         ['conv4_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2  (None, 32, 32, 1024)         263168    ['conv4_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNo  (None, 32, 32, 1024)         4096      ['conv4_block2_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)      (None, 32, 32, 1024)         0         ['conv4_block1_out[0][0]',    \n",
      "                                                                     'conv4_block2_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activati  (None, 32, 32, 1024)         0         ['conv4_block2_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2  (None, 32, 32, 256)          262400    ['conv4_block2_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNo  (None, 32, 32, 256)          1024      ['conv4_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activ  (None, 32, 32, 256)          0         ['conv4_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2  (None, 32, 32, 256)          590080    ['conv4_block3_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNo  (None, 32, 32, 256)          1024      ['conv4_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activ  (None, 32, 32, 256)          0         ['conv4_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2  (None, 32, 32, 1024)         263168    ['conv4_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNo  (None, 32, 32, 1024)         4096      ['conv4_block3_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)      (None, 32, 32, 1024)         0         ['conv4_block2_out[0][0]',    \n",
      "                                                                     'conv4_block3_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activati  (None, 32, 32, 1024)         0         ['conv4_block3_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2  (None, 32, 32, 256)          262400    ['conv4_block3_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNo  (None, 32, 32, 256)          1024      ['conv4_block4_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activ  (None, 32, 32, 256)          0         ['conv4_block4_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2  (None, 32, 32, 256)          590080    ['conv4_block4_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNo  (None, 32, 32, 256)          1024      ['conv4_block4_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activ  (None, 32, 32, 256)          0         ['conv4_block4_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2  (None, 32, 32, 1024)         263168    ['conv4_block4_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNo  (None, 32, 32, 1024)         4096      ['conv4_block4_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)      (None, 32, 32, 1024)         0         ['conv4_block3_out[0][0]',    \n",
      "                                                                     'conv4_block4_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activati  (None, 32, 32, 1024)         0         ['conv4_block4_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2  (None, 32, 32, 256)          262400    ['conv4_block4_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNo  (None, 32, 32, 256)          1024      ['conv4_block5_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activ  (None, 32, 32, 256)          0         ['conv4_block5_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2  (None, 32, 32, 256)          590080    ['conv4_block5_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNo  (None, 32, 32, 256)          1024      ['conv4_block5_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activ  (None, 32, 32, 256)          0         ['conv4_block5_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2  (None, 32, 32, 1024)         263168    ['conv4_block5_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNo  (None, 32, 32, 1024)         4096      ['conv4_block5_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)      (None, 32, 32, 1024)         0         ['conv4_block4_out[0][0]',    \n",
      "                                                                     'conv4_block5_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activati  (None, 32, 32, 1024)         0         ['conv4_block5_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2  (None, 32, 32, 256)          262400    ['conv4_block5_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNo  (None, 32, 32, 256)          1024      ['conv4_block6_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activ  (None, 32, 32, 256)          0         ['conv4_block6_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2  (None, 32, 32, 256)          590080    ['conv4_block6_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNo  (None, 32, 32, 256)          1024      ['conv4_block6_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activ  (None, 32, 32, 256)          0         ['conv4_block6_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2  (None, 32, 32, 1024)         263168    ['conv4_block6_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNo  (None, 32, 32, 1024)         4096      ['conv4_block6_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)      (None, 32, 32, 1024)         0         ['conv4_block5_out[0][0]',    \n",
      "                                                                     'conv4_block6_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activati  (None, 32, 32, 1024)         0         ['conv4_block6_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTr  (None, 64, 64, 512)          2097664   ['conv4_block6_out[0][0]']    \n",
      " anspose)                                                                                         \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 64, 64, 1024)         0         ['conv2d_transpose[0][0]',    \n",
      "                                                                     'conv3_block4_out[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 64, 64, 512)          4719104   ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 64, 64, 512)          2048      ['conv2d[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation (Activation)     (None, 64, 64, 512)          0         ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 64, 64, 512)          2359808   ['activation[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 64, 64, 512)          2048      ['conv2d_1[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)   (None, 64, 64, 512)          0         ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " global_average_pooling2d (  (None, 512)                  0         ['activation_1[0][0]']        \n",
      " GlobalAveragePooling2D)                                                                          \n",
      "                                                                                                  \n",
      " global_max_pooling2d (Glob  (None, 512)                  0         ['activation_1[0][0]']        \n",
      " alMaxPooling2D)                                                                                  \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 64)                   32768     ['global_average_pooling2d[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'global_max_pooling2d[0][0]']\n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 512)                  32768     ['dense[0][0]',               \n",
      "                                                                     'dense[1][0]']               \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOp  (None, 512)                  0         ['dense_1[0][0]',             \n",
      " Lambda)                                                             'dense_1[1][0]']             \n",
      "                                                                                                  \n",
      " activation_2 (Activation)   (None, 512)                  0         ['tf.__operators__.add[0][0]']\n",
      "                                                                                                  \n",
      " multiply (Multiply)         (None, 64, 64, 512)          0         ['activation_1[0][0]',        \n",
      "                                                                     'activation_2[0][0]']        \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean (TFOpL  (None, 64, 64)               0         ['multiply[0][0]']            \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.math.reduce_max (TFOpLa  (None, 64, 64)               0         ['multiply[0][0]']            \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.expand_dims (TFOpLambda  (None, 64, 64, 1)            0         ['tf.math.reduce_mean[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.expand_dims_1 (TFOpLamb  (None, 64, 64, 1)            0         ['tf.math.reduce_max[0][0]']  \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 64, 64, 2)            0         ['tf.expand_dims[0][0]',      \n",
      " )                                                                   'tf.expand_dims_1[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 64, 64, 1)            99        ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " multiply_1 (Multiply)       (None, 64, 64, 512)          0         ['multiply[0][0]',            \n",
      "                                                                     'conv2d_2[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2D  (None, 128, 128, 256)        524544    ['multiply_1[0][0]']          \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 128, 128, 512)        0         ['conv2d_transpose_1[0][0]',  \n",
      " )                                                                   'conv2_block3_out[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 128, 128, 256)        1179904   ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 128, 128, 256)        1024      ['conv2d_3[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_3 (Activation)   (None, 128, 128, 256)        0         ['batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 128, 128, 256)        590080    ['activation_3[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 128, 128, 256)        1024      ['conv2d_4[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_4 (Activation)   (None, 128, 128, 256)        0         ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1  (None, 256)                  0         ['activation_4[0][0]']        \n",
      "  (GlobalAveragePooling2D)                                                                        \n",
      "                                                                                                  \n",
      " global_max_pooling2d_1 (Gl  (None, 256)                  0         ['activation_4[0][0]']        \n",
      " obalMaxPooling2D)                                                                                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 32)                   8192      ['global_average_pooling2d_1[0\n",
      "                                                                    ][0]',                        \n",
      "                                                                     'global_max_pooling2d_1[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 256)                  8192      ['dense_2[0][0]',             \n",
      "                                                                     'dense_2[1][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TF  (None, 256)                  0         ['dense_3[0][0]',             \n",
      " OpLambda)                                                           'dense_3[1][0]']             \n",
      "                                                                                                  \n",
      " activation_5 (Activation)   (None, 256)                  0         ['tf.__operators__.add_1[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " multiply_2 (Multiply)       (None, 128, 128, 256)        0         ['activation_4[0][0]',        \n",
      "                                                                     'activation_5[0][0]']        \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_1 (TFO  (None, 128, 128)             0         ['multiply_2[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.math.reduce_max_1 (TFOp  (None, 128, 128)             0         ['multiply_2[0][0]']          \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.expand_dims_2 (TFOpLamb  (None, 128, 128, 1)          0         ['tf.math.reduce_mean_1[0][0]'\n",
      " da)                                                                ]                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_3 (TFOpLamb  (None, 128, 128, 1)          0         ['tf.math.reduce_max_1[0][0]']\n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate  (None, 128, 128, 2)          0         ['tf.expand_dims_2[0][0]',    \n",
      " )                                                                   'tf.expand_dims_3[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 128, 128, 1)          99        ['concatenate_3[0][0]']       \n",
      "                                                                                                  \n",
      " multiply_3 (Multiply)       (None, 128, 128, 256)        0         ['multiply_2[0][0]',          \n",
      "                                                                     'conv2d_5[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2D  (None, 256, 256, 128)        131200    ['multiply_3[0][0]']          \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate  (None, 256, 256, 192)        0         ['conv2d_transpose_2[0][0]',  \n",
      " )                                                                   'conv1_relu[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 256, 256, 128)        221312    ['concatenate_4[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (None, 256, 256, 128)        512       ['conv2d_6[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_6 (Activation)   (None, 256, 256, 128)        0         ['batch_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (None, 256, 256, 128)        147584    ['activation_6[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (None, 256, 256, 128)        512       ['conv2d_7[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_7 (Activation)   (None, 256, 256, 128)        0         ['batch_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2  (None, 128)                  0         ['activation_7[0][0]']        \n",
      "  (GlobalAveragePooling2D)                                                                        \n",
      "                                                                                                  \n",
      " global_max_pooling2d_2 (Gl  (None, 128)                  0         ['activation_7[0][0]']        \n",
      " obalMaxPooling2D)                                                                                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 16)                   2048      ['global_average_pooling2d_2[0\n",
      "                                                                    ][0]',                        \n",
      "                                                                     'global_max_pooling2d_2[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 128)                  2048      ['dense_4[0][0]',             \n",
      "                                                                     'dense_4[1][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TF  (None, 128)                  0         ['dense_5[0][0]',             \n",
      " OpLambda)                                                           'dense_5[1][0]']             \n",
      "                                                                                                  \n",
      " activation_8 (Activation)   (None, 128)                  0         ['tf.__operators__.add_2[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " multiply_4 (Multiply)       (None, 256, 256, 128)        0         ['activation_7[0][0]',        \n",
      "                                                                     'activation_8[0][0]']        \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_2 (TFO  (None, 256, 256)             0         ['multiply_4[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.math.reduce_max_2 (TFOp  (None, 256, 256)             0         ['multiply_4[0][0]']          \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.expand_dims_4 (TFOpLamb  (None, 256, 256, 1)          0         ['tf.math.reduce_mean_2[0][0]'\n",
      " da)                                                                ]                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_5 (TFOpLamb  (None, 256, 256, 1)          0         ['tf.math.reduce_max_2[0][0]']\n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate  (None, 256, 256, 2)          0         ['tf.expand_dims_4[0][0]',    \n",
      " )                                                                   'tf.expand_dims_5[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)           (None, 256, 256, 1)          99        ['concatenate_5[0][0]']       \n",
      "                                                                                                  \n",
      " multiply_5 (Multiply)       (None, 256, 256, 128)        0         ['multiply_4[0][0]',          \n",
      "                                                                     'conv2d_8[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2D  (None, 512, 512, 64)         32832     ['multiply_5[0][0]']          \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate  (None, 512, 512, 67)         0         ['conv2d_transpose_3[0][0]',  \n",
      " )                                                                   'input_1[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (None, 512, 512, 64)         38656     ['concatenate_6[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (None, 512, 512, 64)         256       ['conv2d_9[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_9 (Activation)   (None, 512, 512, 64)         0         ['batch_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (None, 512, 512, 64)         36928     ['activation_9[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_7 (Bat  (None, 512, 512, 64)         256       ['conv2d_10[0][0]']           \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_10 (Activation)  (None, 512, 512, 64)         0         ['batch_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " global_average_pooling2d_3  (None, 64)                   0         ['activation_10[0][0]']       \n",
      "  (GlobalAveragePooling2D)                                                                        \n",
      "                                                                                                  \n",
      " global_max_pooling2d_3 (Gl  (None, 64)                   0         ['activation_10[0][0]']       \n",
      " obalMaxPooling2D)                                                                                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 8)                    512       ['global_average_pooling2d_3[0\n",
      "                                                                    ][0]',                        \n",
      "                                                                     'global_max_pooling2d_3[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, 64)                   512       ['dense_6[0][0]',             \n",
      "                                                                     'dense_6[1][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TF  (None, 64)                   0         ['dense_7[0][0]',             \n",
      " OpLambda)                                                           'dense_7[1][0]']             \n",
      "                                                                                                  \n",
      " activation_11 (Activation)  (None, 64)                   0         ['tf.__operators__.add_3[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " multiply_6 (Multiply)       (None, 512, 512, 64)         0         ['activation_10[0][0]',       \n",
      "                                                                     'activation_11[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_3 (TFO  (None, 512, 512)             0         ['multiply_6[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.math.reduce_max_3 (TFOp  (None, 512, 512)             0         ['multiply_6[0][0]']          \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.expand_dims_6 (TFOpLamb  (None, 512, 512, 1)          0         ['tf.math.reduce_mean_3[0][0]'\n",
      " da)                                                                ]                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_7 (TFOpLamb  (None, 512, 512, 1)          0         ['tf.math.reduce_max_3[0][0]']\n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate  (None, 512, 512, 2)          0         ['tf.expand_dims_6[0][0]',    \n",
      " )                                                                   'tf.expand_dims_7[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (None, 512, 512, 1)          99        ['concatenate_7[0][0]']       \n",
      "                                                                                                  \n",
      " multiply_7 (Multiply)       (None, 512, 512, 64)         0         ['multiply_6[0][0]',          \n",
      "                                                                     'conv2d_11[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (None, 512, 512, 1)          65        ['multiply_7[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 20763981 (79.21 MB)\n",
      "Trainable params: 20729549 (79.08 MB)\n",
      "Non-trainable params: 34432 (134.50 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Video and Read First Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160 3840\n"
     ]
    }
   ],
   "source": [
    "vs = cv2.VideoCapture(input_video_path)\n",
    "_, frame = vs.read()\n",
    "H, W, _ = frame.shape\n",
    "vs.release()\n",
    "\n",
    "print(H, W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output  Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourcc = cv2.VideoWriter_fourcc('M','J','P','G')\n",
    "fps = 30\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (W, H), True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 648ms/step\n",
      "1/1 [==============================] - 1s 651ms/step\n",
      "1/1 [==============================] - 1s 652ms/step\n",
      "1/1 [==============================] - 1s 644ms/step\n",
      "1/1 [==============================] - 1s 644ms/step\n",
      "1/1 [==============================] - 1s 645ms/step\n",
      "1/1 [==============================] - 1s 644ms/step\n",
      "1/1 [==============================] - 1s 640ms/step\n",
      "1/1 [==============================] - 1s 655ms/step\n",
      "1/1 [==============================] - 1s 638ms/step\n",
      "1/1 [==============================] - 1s 649ms/step\n",
      "1/1 [==============================] - 1s 642ms/step\n",
      "1/1 [==============================] - 1s 659ms/step\n",
      "1/1 [==============================] - 1s 656ms/step\n",
      "1/1 [==============================] - 1s 644ms/step\n",
      "1/1 [==============================] - 1s 648ms/step\n",
      "1/1 [==============================] - 1s 649ms/step\n",
      "1/1 [==============================] - 1s 657ms/step\n",
      "1/1 [==============================] - 1s 659ms/step\n",
      "1/1 [==============================] - 1s 663ms/step\n",
      "1/1 [==============================] - 1s 655ms/step\n",
      "1/1 [==============================] - 1s 677ms/step\n",
      "1/1 [==============================] - 1s 658ms/step\n",
      "1/1 [==============================] - 1s 659ms/step\n",
      "1/1 [==============================] - 1s 663ms/step\n",
      "1/1 [==============================] - 1s 657ms/step\n",
      "1/1 [==============================] - 1s 659ms/step\n",
      "1/1 [==============================] - 1s 660ms/step\n",
      "1/1 [==============================] - 1s 665ms/step\n",
      "1/1 [==============================] - 1s 680ms/step\n",
      "1/1 [==============================] - 1s 653ms/step\n",
      "1/1 [==============================] - 1s 663ms/step\n",
      "1/1 [==============================] - 1s 658ms/step\n",
      "1/1 [==============================] - 1s 679ms/step\n",
      "1/1 [==============================] - 1s 654ms/step\n",
      "1/1 [==============================] - 1s 668ms/step\n",
      "1/1 [==============================] - 1s 654ms/step\n",
      "1/1 [==============================] - 1s 673ms/step\n",
      "1/1 [==============================] - 1s 651ms/step\n",
      "1/1 [==============================] - 1s 653ms/step\n",
      "1/1 [==============================] - 1s 824ms/step\n",
      "1/1 [==============================] - 1s 677ms/step\n",
      "1/1 [==============================] - 1s 779ms/step\n",
      "1/1 [==============================] - 1s 671ms/step\n",
      "1/1 [==============================] - 1s 676ms/step\n",
      "1/1 [==============================] - 1s 673ms/step\n",
      "1/1 [==============================] - 1s 666ms/step\n",
      "1/1 [==============================] - 1s 670ms/step\n",
      "1/1 [==============================] - 1s 672ms/step\n",
      "1/1 [==============================] - 1s 690ms/step\n",
      "1/1 [==============================] - 1s 674ms/step\n",
      "1/1 [==============================] - 1s 662ms/step\n",
      "1/1 [==============================] - 1s 665ms/step\n",
      "1/1 [==============================] - 1s 669ms/step\n",
      "1/1 [==============================] - 1s 695ms/step\n",
      "1/1 [==============================] - 1s 666ms/step\n",
      "1/1 [==============================] - 1s 682ms/step\n",
      "1/1 [==============================] - 1s 669ms/step\n",
      "1/1 [==============================] - 1s 669ms/step\n",
      "1/1 [==============================] - 1s 657ms/step\n",
      "1/1 [==============================] - 1s 654ms/step\n",
      "1/1 [==============================] - 1s 655ms/step\n",
      "1/1 [==============================] - 1s 657ms/step\n",
      "1/1 [==============================] - 1s 653ms/step\n",
      "1/1 [==============================] - 1s 657ms/step\n",
      "1/1 [==============================] - 1s 682ms/step\n",
      "1/1 [==============================] - 1s 660ms/step\n",
      "1/1 [==============================] - 1s 654ms/step\n",
      "1/1 [==============================] - 1s 660ms/step\n",
      "1/1 [==============================] - 1s 713ms/step\n",
      "1/1 [==============================] - 1s 656ms/step\n",
      "1/1 [==============================] - 1s 657ms/step\n",
      "1/1 [==============================] - 1s 672ms/step\n",
      "1/1 [==============================] - 1s 668ms/step\n",
      "1/1 [==============================] - 1s 664ms/step\n",
      "1/1 [==============================] - 1s 659ms/step\n",
      "1/1 [==============================] - 1s 680ms/step\n",
      "1/1 [==============================] - 1s 667ms/step\n",
      "1/1 [==============================] - 1s 661ms/step\n",
      "1/1 [==============================] - 1s 659ms/step\n",
      "1/1 [==============================] - 1s 666ms/step\n",
      "1/1 [==============================] - 1s 677ms/step\n",
      "1/1 [==============================] - 1s 674ms/step\n",
      "1/1 [==============================] - 1s 668ms/step\n",
      "1/1 [==============================] - 1s 661ms/step\n",
      "1/1 [==============================] - 1s 663ms/step\n",
      "1/1 [==============================] - 1s 671ms/step\n",
      "1/1 [==============================] - 1s 674ms/step\n",
      "1/1 [==============================] - 1s 657ms/step\n",
      "1/1 [==============================] - 1s 653ms/step\n",
      "1/1 [==============================] - 1s 649ms/step\n",
      "1/1 [==============================] - 1s 653ms/step\n",
      "1/1 [==============================] - 1s 654ms/step\n",
      "1/1 [==============================] - 1s 660ms/step\n",
      "1/1 [==============================] - 1s 656ms/step\n",
      "1/1 [==============================] - 1s 648ms/step\n",
      "1/1 [==============================] - 1s 660ms/step\n",
      "1/1 [==============================] - 1s 655ms/step\n",
      "1/1 [==============================] - 1s 651ms/step\n",
      "1/1 [==============================] - 1s 678ms/step\n",
      "1/1 [==============================] - 1s 654ms/step\n",
      "1/1 [==============================] - 1s 659ms/step\n",
      "1/1 [==============================] - 1s 716ms/step\n",
      "1/1 [==============================] - 1s 683ms/step\n",
      "1/1 [==============================] - 1s 676ms/step\n",
      "1/1 [==============================] - 1s 675ms/step\n",
      "1/1 [==============================] - 1s 751ms/step\n",
      "1/1 [==============================] - 1s 679ms/step\n",
      "1/1 [==============================] - 1s 708ms/step\n",
      "1/1 [==============================] - 1s 673ms/step\n",
      "1/1 [==============================] - 1s 673ms/step\n",
      "1/1 [==============================] - 1s 681ms/step\n",
      "1/1 [==============================] - 1s 679ms/step\n",
      "1/1 [==============================] - 1s 664ms/step\n",
      "1/1 [==============================] - 1s 661ms/step\n",
      "1/1 [==============================] - 1s 689ms/step\n",
      "1/1 [==============================] - 1s 680ms/step\n",
      "1/1 [==============================] - 1s 714ms/step\n",
      "1/1 [==============================] - 1s 807ms/step\n",
      "1/1 [==============================] - 1s 877ms/step\n",
      "1/1 [==============================] - 1s 883ms/step\n",
      "1/1 [==============================] - 1s 849ms/step\n",
      "1/1 [==============================] - 1s 850ms/step\n",
      "1/1 [==============================] - 1s 706ms/step\n",
      "1/1 [==============================] - 1s 671ms/step\n",
      "1/1 [==============================] - 1s 703ms/step\n",
      "1/1 [==============================] - 1s 727ms/step\n",
      "1/1 [==============================] - 1s 673ms/step\n",
      "1/1 [==============================] - 1s 688ms/step\n",
      "1/1 [==============================] - 1s 693ms/step\n",
      "1/1 [==============================] - 1s 684ms/step\n",
      "1/1 [==============================] - 1s 671ms/step\n",
      "1/1 [==============================] - 1s 682ms/step\n",
      "1/1 [==============================] - 1s 673ms/step\n",
      "1/1 [==============================] - 1s 683ms/step\n",
      "1/1 [==============================] - 1s 673ms/step\n",
      "1/1 [==============================] - 1s 674ms/step\n",
      "1/1 [==============================] - 1s 672ms/step\n",
      "1/1 [==============================] - 1s 677ms/step\n",
      "1/1 [==============================] - 1s 673ms/step\n",
      "1/1 [==============================] - 1s 676ms/step\n",
      "1/1 [==============================] - 1s 681ms/step\n",
      "1/1 [==============================] - 1s 673ms/step\n",
      "1/1 [==============================] - 1s 681ms/step\n",
      "1/1 [==============================] - 1s 673ms/step\n",
      "1/1 [==============================] - 1s 668ms/step\n",
      "1/1 [==============================] - 1s 671ms/step\n",
      "1/1 [==============================] - 1s 678ms/step\n",
      "1/1 [==============================] - 1s 678ms/step\n",
      "1/1 [==============================] - 1s 685ms/step\n",
      "1/1 [==============================] - 1s 676ms/step\n",
      "1/1 [==============================] - 1s 669ms/step\n",
      "1/1 [==============================] - 1s 692ms/step\n",
      "1/1 [==============================] - 1s 680ms/step\n",
      "1/1 [==============================] - 1s 677ms/step\n",
      "1/1 [==============================] - 1s 690ms/step\n",
      "1/1 [==============================] - 1s 694ms/step\n",
      "1/1 [==============================] - 1s 679ms/step\n",
      "1/1 [==============================] - 1s 676ms/step\n",
      "1/1 [==============================] - 1s 686ms/step\n",
      "1/1 [==============================] - 1s 675ms/step\n",
      "1/1 [==============================] - 1s 675ms/step\n",
      "1/1 [==============================] - 1s 681ms/step\n",
      "1/1 [==============================] - 1s 748ms/step\n",
      "1/1 [==============================] - 1s 711ms/step\n",
      "1/1 [==============================] - 1s 700ms/step\n",
      "1/1 [==============================] - 1s 689ms/step\n",
      "1/1 [==============================] - 1s 700ms/step\n",
      "1/1 [==============================] - 1s 693ms/step\n",
      "1/1 [==============================] - 1s 701ms/step\n",
      "1/1 [==============================] - 1s 754ms/step\n",
      "1/1 [==============================] - 1s 676ms/step\n",
      "1/1 [==============================] - 1s 679ms/step\n",
      "1/1 [==============================] - 1s 733ms/step\n",
      "1/1 [==============================] - 1s 745ms/step\n",
      "1/1 [==============================] - 1s 690ms/step\n",
      "1/1 [==============================] - 1s 693ms/step\n",
      "1/1 [==============================] - 1s 715ms/step\n",
      "1/1 [==============================] - 1s 686ms/step\n",
      "1/1 [==============================] - 1s 724ms/step\n",
      "1/1 [==============================] - 1s 686ms/step\n",
      "1/1 [==============================] - 1s 685ms/step\n",
      "1/1 [==============================] - 1s 703ms/step\n",
      "1/1 [==============================] - 1s 686ms/step\n",
      "1/1 [==============================] - 1s 701ms/step\n",
      "1/1 [==============================] - 1s 711ms/step\n",
      "1/1 [==============================] - 1s 689ms/step\n",
      "1/1 [==============================] - 1s 701ms/step\n",
      "1/1 [==============================] - 1s 688ms/step\n",
      "1/1 [==============================] - 1s 683ms/step\n",
      "1/1 [==============================] - 1s 687ms/step\n",
      "1/1 [==============================] - 1s 687ms/step\n",
      "1/1 [==============================] - 1s 686ms/step\n",
      "1/1 [==============================] - 1s 695ms/step\n",
      "1/1 [==============================] - 1s 725ms/step\n",
      "1/1 [==============================] - 1s 698ms/step\n",
      "1/1 [==============================] - 1s 685ms/step\n",
      "1/1 [==============================] - 1s 691ms/step\n",
      "1/1 [==============================] - 1s 706ms/step\n",
      "1/1 [==============================] - 1s 697ms/step\n",
      "1/1 [==============================] - 1s 730ms/step\n",
      "1/1 [==============================] - 1s 705ms/step\n",
      "1/1 [==============================] - 1s 691ms/step\n",
      "1/1 [==============================] - 1s 685ms/step\n",
      "1/1 [==============================] - 1s 681ms/step\n",
      "1/1 [==============================] - 1s 679ms/step\n",
      "1/1 [==============================] - 1s 679ms/step\n",
      "1/1 [==============================] - 1s 690ms/step\n",
      "1/1 [==============================] - 1s 716ms/step\n",
      "1/1 [==============================] - 1s 691ms/step\n",
      "1/1 [==============================] - 1s 690ms/step\n",
      "1/1 [==============================] - 1s 682ms/step\n",
      "1/1 [==============================] - 1s 708ms/step\n",
      "1/1 [==============================] - 1s 680ms/step\n",
      "1/1 [==============================] - 1s 673ms/step\n",
      "1/1 [==============================] - 1s 681ms/step\n",
      "1/1 [==============================] - 1s 683ms/step\n",
      "1/1 [==============================] - 1s 678ms/step\n",
      "1/1 [==============================] - 1s 673ms/step\n",
      "1/1 [==============================] - 1s 679ms/step\n",
      "1/1 [==============================] - 1s 674ms/step\n",
      "1/1 [==============================] - 1s 670ms/step\n",
      "1/1 [==============================] - 1s 677ms/step\n",
      "1/1 [==============================] - 1s 679ms/step\n",
      "1/1 [==============================] - 1s 680ms/step\n",
      "1/1 [==============================] - 1s 672ms/step\n",
      "1/1 [==============================] - 1s 679ms/step\n",
      "1/1 [==============================] - 1s 674ms/step\n",
      "1/1 [==============================] - 1s 729ms/step\n",
      "1/1 [==============================] - 1s 702ms/step\n",
      "1/1 [==============================] - 1s 728ms/step\n",
      "1/1 [==============================] - 1s 695ms/step\n",
      "1/1 [==============================] - 1s 715ms/step\n",
      "1/1 [==============================] - 1s 705ms/step\n",
      "1/1 [==============================] - 1s 680ms/step\n",
      "1/1 [==============================] - 1s 678ms/step\n",
      "1/1 [==============================] - 1s 674ms/step\n",
      "1/1 [==============================] - 1s 672ms/step\n",
      "1/1 [==============================] - 1s 691ms/step\n",
      "1/1 [==============================] - 1s 679ms/step\n",
      "1/1 [==============================] - 1s 678ms/step\n",
      "1/1 [==============================] - 1s 713ms/step\n",
      "1/1 [==============================] - 1s 686ms/step\n",
      "1/1 [==============================] - 1s 679ms/step\n",
      "1/1 [==============================] - 1s 674ms/step\n",
      "1/1 [==============================] - 1s 680ms/step\n",
      "1/1 [==============================] - 1s 680ms/step\n",
      "1/1 [==============================] - 1s 672ms/step\n",
      "1/1 [==============================] - 1s 675ms/step\n",
      "1/1 [==============================] - 1s 687ms/step\n",
      "1/1 [==============================] - 1s 670ms/step\n",
      "1/1 [==============================] - 1s 717ms/step\n",
      "1/1 [==============================] - 1s 684ms/step\n",
      "1/1 [==============================] - 1s 679ms/step\n",
      "1/1 [==============================] - 1s 685ms/step\n",
      "1/1 [==============================] - 1s 676ms/step\n",
      "1/1 [==============================] - 1s 673ms/step\n",
      "1/1 [==============================] - 1s 677ms/step\n",
      "1/1 [==============================] - 1s 680ms/step\n",
      "1/1 [==============================] - 1s 673ms/step\n",
      "1/1 [==============================] - 1s 684ms/step\n",
      "1/1 [==============================] - 1s 683ms/step\n",
      "1/1 [==============================] - 1s 676ms/step\n",
      "1/1 [==============================] - 1s 673ms/step\n",
      "1/1 [==============================] - 1s 677ms/step\n",
      "1/1 [==============================] - 1s 772ms/step\n",
      "1/1 [==============================] - 1s 675ms/step\n",
      "1/1 [==============================] - 1s 669ms/step\n",
      "1/1 [==============================] - 1s 671ms/step\n",
      "1/1 [==============================] - 1s 673ms/step\n",
      "1/1 [==============================] - 1s 670ms/step\n",
      "1/1 [==============================] - 1s 672ms/step\n",
      "1/1 [==============================] - 1s 675ms/step\n",
      "1/1 [==============================] - 1s 672ms/step\n",
      "1/1 [==============================] - 1s 673ms/step\n",
      "1/1 [==============================] - 1s 668ms/step\n",
      "1/1 [==============================] - 1s 677ms/step\n",
      "1/1 [==============================] - 1s 674ms/step\n",
      "1/1 [==============================] - 1s 673ms/step\n",
      "1/1 [==============================] - 1s 670ms/step\n",
      "1/1 [==============================] - 1s 683ms/step\n",
      "1/1 [==============================] - 1s 670ms/step\n",
      "1/1 [==============================] - 1s 709ms/step\n",
      "1/1 [==============================] - 1s 684ms/step\n",
      "1/1 [==============================] - 1s 692ms/step\n",
      "1/1 [==============================] - 1s 681ms/step\n",
      "1/1 [==============================] - 1s 681ms/step\n",
      "1/1 [==============================] - 1s 681ms/step\n",
      "1/1 [==============================] - 1s 685ms/step\n",
      "1/1 [==============================] - 1s 679ms/step\n",
      "1/1 [==============================] - 1s 678ms/step\n",
      "1/1 [==============================] - 1s 676ms/step\n",
      "1/1 [==============================] - 1s 688ms/step\n",
      "1/1 [==============================] - 1s 687ms/step\n",
      "1/1 [==============================] - 1s 681ms/step\n",
      "1/1 [==============================] - 1s 685ms/step\n",
      "1/1 [==============================] - 1s 716ms/step\n",
      "1/1 [==============================] - 1s 707ms/step\n",
      "1/1 [==============================] - 1s 691ms/step\n",
      "1/1 [==============================] - 1s 737ms/step\n",
      "1/1 [==============================] - 1s 673ms/step\n",
      "1/1 [==============================] - 1s 671ms/step\n",
      "1/1 [==============================] - 1s 671ms/step\n",
      "1/1 [==============================] - 1s 671ms/step\n",
      "1/1 [==============================] - 1s 672ms/step\n",
      "1/1 [==============================] - 1s 674ms/step\n",
      "1/1 [==============================] - 1s 665ms/step\n",
      "1/1 [==============================] - 1s 671ms/step\n",
      "1/1 [==============================] - 1s 673ms/step\n",
      "1/1 [==============================] - 1s 678ms/step\n",
      "1/1 [==============================] - 1s 674ms/step\n",
      "1/1 [==============================] - 1s 723ms/step\n",
      "1/1 [==============================] - 1s 701ms/step\n",
      "1/1 [==============================] - 1s 713ms/step\n",
      "1/1 [==============================] - 1s 701ms/step\n",
      "1/1 [==============================] - 1s 682ms/step\n",
      "1/1 [==============================] - 1s 689ms/step\n",
      "1/1 [==============================] - 1s 743ms/step\n",
      "1/1 [==============================] - 1s 690ms/step\n",
      "1/1 [==============================] - 1s 702ms/step\n",
      "1/1 [==============================] - 1s 688ms/step\n",
      "1/1 [==============================] - 1s 697ms/step\n",
      "1/1 [==============================] - 1s 682ms/step\n",
      "1/1 [==============================] - 1s 707ms/step\n",
      "1/1 [==============================] - 1s 683ms/step\n",
      "1/1 [==============================] - 1s 677ms/step\n",
      "1/1 [==============================] - 1s 680ms/step\n",
      "1/1 [==============================] - 1s 685ms/step\n",
      "1/1 [==============================] - 1s 687ms/step\n",
      "1/1 [==============================] - 1s 684ms/step\n",
      "1/1 [==============================] - 1s 665ms/step\n",
      "1/1 [==============================] - 1s 666ms/step\n",
      "1/1 [==============================] - 1s 672ms/step\n",
      "1/1 [==============================] - 1s 678ms/step\n",
      "1/1 [==============================] - 1s 687ms/step\n",
      "1/1 [==============================] - 1s 685ms/step\n",
      "1/1 [==============================] - 1s 689ms/step\n",
      "1/1 [==============================] - 1s 676ms/step\n",
      "1/1 [==============================] - 1s 675ms/step\n",
      "1/1 [==============================] - 1s 685ms/step\n",
      "1/1 [==============================] - 1s 684ms/step\n",
      "1/1 [==============================] - 1s 671ms/step\n",
      "1/1 [==============================] - 1s 668ms/step\n",
      "1/1 [==============================] - 1s 667ms/step\n",
      "1/1 [==============================] - 1s 673ms/step\n",
      "1/1 [==============================] - 1s 671ms/step\n",
      "1/1 [==============================] - 1s 670ms/step\n",
      "1/1 [==============================] - 1s 671ms/step\n",
      "1/1 [==============================] - 1s 674ms/step\n",
      "1/1 [==============================] - 1s 673ms/step\n",
      "1/1 [==============================] - 1s 668ms/step\n",
      "1/1 [==============================] - 1s 670ms/step\n",
      "1/1 [==============================] - 1s 672ms/step\n",
      "1/1 [==============================] - 1s 669ms/step\n",
      "1/1 [==============================] - 1s 679ms/step\n",
      "1/1 [==============================] - 1s 689ms/step\n",
      "1/1 [==============================] - 1s 689ms/step\n",
      "1/1 [==============================] - 1s 670ms/step\n",
      "1/1 [==============================] - 1s 672ms/step\n",
      "1/1 [==============================] - 1s 675ms/step\n",
      "1/1 [==============================] - 1s 671ms/step\n",
      "1/1 [==============================] - 1s 676ms/step\n",
      "1/1 [==============================] - 1s 691ms/step\n",
      "1/1 [==============================] - 1s 692ms/step\n",
      "1/1 [==============================] - 1s 676ms/step\n",
      "1/1 [==============================] - 1s 677ms/step\n",
      "1/1 [==============================] - 1s 684ms/step\n",
      "1/1 [==============================] - 1s 682ms/step\n",
      "1/1 [==============================] - 1s 683ms/step\n",
      "1/1 [==============================] - 1s 692ms/step\n",
      "1/1 [==============================] - 1s 684ms/step\n",
      "1/1 [==============================] - 1s 700ms/step\n",
      "1/1 [==============================] - 1s 682ms/step\n",
      "1/1 [==============================] - 1s 672ms/step\n",
      "1/1 [==============================] - 1s 667ms/step\n",
      "1/1 [==============================] - 1s 670ms/step\n",
      "1/1 [==============================] - 1s 670ms/step\n",
      "1/1 [==============================] - 1s 660ms/step\n",
      "1/1 [==============================] - 1s 671ms/step\n",
      "1/1 [==============================] - 1s 669ms/step\n",
      "1/1 [==============================] - 1s 663ms/step\n",
      "1/1 [==============================] - 1s 668ms/step\n",
      "1/1 [==============================] - 1s 674ms/step\n",
      "1/1 [==============================] - 1s 692ms/step\n",
      "1/1 [==============================] - 1s 675ms/step\n",
      "1/1 [==============================] - 1s 673ms/step\n",
      "1/1 [==============================] - 1s 740ms/step\n",
      "1/1 [==============================] - 1s 671ms/step\n",
      "1/1 [==============================] - 1s 675ms/step\n",
      "1/1 [==============================] - 1s 701ms/step\n",
      "1/1 [==============================] - 1s 680ms/step\n",
      "1/1 [==============================] - 1s 679ms/step\n",
      "1/1 [==============================] - 1s 677ms/step\n",
      "1/1 [==============================] - 1s 680ms/step\n",
      "1/1 [==============================] - 1s 681ms/step\n",
      "1/1 [==============================] - 1s 679ms/step\n",
      "1/1 [==============================] - 1s 684ms/step\n",
      "1/1 [==============================] - 1s 675ms/step\n",
      "1/1 [==============================] - 1s 679ms/step\n",
      "1/1 [==============================] - 1s 683ms/step\n",
      "1/1 [==============================] - 1s 702ms/step\n",
      "1/1 [==============================] - 1s 675ms/step\n",
      "1/1 [==============================] - 1s 687ms/step\n",
      "1/1 [==============================] - 1s 673ms/step\n",
      "1/1 [==============================] - 1s 670ms/step\n",
      "1/1 [==============================] - 1s 672ms/step\n",
      "1/1 [==============================] - 1s 663ms/step\n",
      "1/1 [==============================] - 1s 669ms/step\n",
      "1/1 [==============================] - 1s 671ms/step\n",
      "Process Completed!\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret == False:\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        break\n",
    "        \n",
    "    H, W, _ = frame.shape\n",
    "    ori_frame = frame\n",
    "    \n",
    "    frame = cv2.resize(frame, (width, height))\n",
    "    frame = frame/255\n",
    "    frame = np.expand_dims(frame, axis=0)\n",
    "    \n",
    "    \n",
    "    mask = model.predict(frame)[0]\n",
    "    mask = cv2.resize(mask, (W, H))\n",
    "    mask = mask > 0.5\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    mask = np.concatenate([mask, mask, mask], axis=-1) * 255\n",
    "    \n",
    "    mask = mask.astype(np.float32)\n",
    "    ori_frame = ori_frame.astype(np.float32)\n",
    "    \n",
    "    alpha = 0.6\n",
    "    output = cv2.addWeighted(mask, alpha, ori_frame, 1-alpha, 0)\n",
    "    output = output.astype(np.uint8)\n",
    "    \n",
    "    out.write(output)\n",
    "    \n",
    "print(\"Process Completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
